{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE7KNzPPVrVV"
      },
      "source": [
        "# Demonstrate easy integration of the wandb client into pre-existing Beverage Packaging Waste dataset.\n",
        "\n",
        "Reference: https://wandb.ai/sauravm/Optimizers/reports/How-to-Compare-Keras-Optimizers-in-Tensorflow-for-Deep-Learning--VmlldzoxNjU1OTA4\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "# Packages ğŸ“¦ and Basic Setup\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1WtoaOHVrVh"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "## Install the latest version of wandb client ğŸ”¥ğŸ”¥\n",
        "!pip install -q --upgrade wandb\n",
        "\n",
        "## Import Packages\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wandb\n",
        "from wandb.keras import WandbMetricsLogger\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY-KGVxJ-CR5",
        "outputId": "a554cbed-5e13-4c21-bf32-acb4c955f26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H74l2DoDI2XD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "840914ac-6e0c-416e-a61a-ffb088c8513b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:mpvrn8tg) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">blackberry-pie-2</strong> at: <a href='https://wandb.ai/leoliu11/Optimizers/runs/mpvrn8tg' target=\"_blank\">https://wandb.ai/leoliu11/Optimizers/runs/mpvrn8tg</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>/content/wandb/run-20230314_194156-mpvrn8tg/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:mpvrn8tg). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230314_213346-57k48fyx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/leoliu11/Optimizers/runs/57k48fyx' target=\"_blank\">peanut-butter-pie-3</a></strong> to <a href='https://wandb.ai/leoliu11/Optimizers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/leoliu11/Optimizers' target=\"_blank\">https://wandb.ai/leoliu11/Optimizers</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/leoliu11/Optimizers/runs/57k48fyx' target=\"_blank\">https://wandb.ai/leoliu11/Optimizers/runs/57k48fyx</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb.init(project='Batch size')\n",
        "\n",
        "# Feel free to change these and experiment !!\n",
        "config = wandb.config\n",
        "config.epochs = 30\n",
        "config.batch_size = 32  # <-- Change this variable to experiment with various batch_size\n",
        "config.img_height = 160 # <-- Change this variable to experiment with various image_size\n",
        "config.img_width = 160  # <-- Change this variable to experiment with various image_size\n",
        "config.validation_split = 0.2\n",
        "config.seed = 42\n",
        "config.optimizer = \"adam\" # <-- Change this variable to experiment with various optimizers\n",
        "\n",
        "wandb.config.update(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "# ğŸ’¿ The Dataset\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive #Connect to my Google Drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/My Drive/Colab Notebooks/rawimgs' #Directories of Google Drive\n",
        "os.chdir(path) #Go to path\n",
        "os.listdir(path) #List out files in the path\n",
        "print(\"Files and directories in '\", path, \"' :\", os.listdir(path))\n",
        "\n",
        "'''\n",
        "What datatypes are we looking at? What is the file structure?\n",
        "'''\n",
        "\n",
        "classes = sorted(os.listdir(path))\n",
        "print(classes)\n",
        "\n",
        "n_files = {}\n",
        "filetypes = {}\n",
        "for dirname, _, filenames in os.walk(path):\n",
        "    n_files[dirname] = 0\n",
        "    for filename in filenames:\n",
        "        n_files[dirname] += 1   \n",
        "        extension = filename.split('.')[-1]\n",
        "        if extension in filetypes.keys():\n",
        "            filetypes[extension] += 1\n",
        "        else:    \n",
        "            filetypes[extension] = 1\n",
        "\n",
        "for directory, counts in n_files.items():\n",
        "    print(f'number of files {directory} {counts}') \n",
        "\n",
        "for filetype, counts in filetypes.items():\n",
        "    print(f'number of files of filetype {filetype} {counts}') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKLS8NKQolCp",
        "outputId": "cffd7dfc-f7b6-4527-e0e2-21f6fd6143da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Files and directories in ' /content/drive/My Drive/Colab Notebooks/rawimgs ' : ['AluCan', 'Glass', 'PET', 'HDPEM', 'Other Background ']\n",
            "['AluCan', 'Glass', 'HDPEM', 'Other Background ', 'PET']\n",
            "number of files /content/drive/My Drive/Colab Notebooks/rawimgs 0\n",
            "number of files /content/drive/My Drive/Colab Notebooks/rawimgs/AluCan 1060\n",
            "number of files /content/drive/My Drive/Colab Notebooks/rawimgs/Glass 1232\n",
            "number of files /content/drive/My Drive/Colab Notebooks/rawimgs/PET 1508\n",
            "number of files /content/drive/My Drive/Colab Notebooks/rawimgs/HDPEM 1028\n",
            "number of files /content/drive/My Drive/Colab Notebooks/rawimgs/Other Background  1027\n",
            "number of files of filetype jpg 4706\n",
            "number of files of filetype JPG 1141\n",
            "number of files of filetype HEIC 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIR0kRZiI_AT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d92c72-3193-4dec-de6e-87647a51506c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5847 files belonging to 5 classes.\n",
            "Using 4678 files for training.\n",
            "Found 5847 files belonging to 5 classes.\n",
            "Using 1169 files for validation.\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "\n",
        "data_dir = pathlib.Path(path)\n",
        "\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "wandb.config.update({\"Image Count\": image_count})\n",
        "\n",
        "## Create tf.Dataset from utility function\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=config.validation_split,\n",
        "  subset=\"training\",\n",
        "  seed=config.seed,\n",
        "  image_size=(config.img_height, config.img_width),\n",
        "  batch_size=config.batch_size)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=config.validation_split,\n",
        "  subset=\"validation\",\n",
        "  seed=config.seed,\n",
        "  image_size=(config.img_height, config.img_width),\n",
        "  batch_size=config.batch_size)\n",
        "\n",
        "## Add Class Names to the Config\n",
        "class_names = train_ds.class_names\n",
        "num_classes = len(class_names)\n",
        "wandb.config.update({\"Class Names\": class_names})\n",
        "wandb.config.update({\"No of Classes\": num_classes})\n",
        "\n",
        "## Apply Optimizations\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "## Normalize the Dataset\n",
        "normalization_layer = layers.Rescaling(1./255)\n",
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcUTyDOPKucd"
      },
      "source": [
        "# âœï¸ Model Architecture\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9J80BAbIMs21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "395bea7a-69d2-4e42-80ff-111789a6965a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        }
      ],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\",\n",
        "                      input_shape=(config.img_height,\n",
        "                                  config.img_width,\n",
        "                                  3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Zeg8zsqXCsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f378607-e86f-48ae-abea-301363822388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4nEcuqgZLbi"
      },
      "source": [
        "#ğŸ§± + ğŸ— = ğŸ  Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWS-vvNaZDag",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62a5ce4e-58e1-4c7b-898e-535da8264d34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "147/147 [==============================] - 513s 790ms/step - loss: 1.1054 - accuracy: 0.5372 - val_loss: 0.9987 - val_accuracy: 0.6168\n",
            "Epoch 2/30\n",
            "147/147 [==============================] - 23s 157ms/step - loss: 0.7106 - accuracy: 0.7277 - val_loss: 0.9994 - val_accuracy: 0.6364\n",
            "Epoch 3/30\n",
            "147/147 [==============================] - 21s 146ms/step - loss: 0.6038 - accuracy: 0.7708 - val_loss: 0.8238 - val_accuracy: 0.7169\n",
            "Epoch 4/30\n",
            "147/147 [==============================] - 23s 158ms/step - loss: 0.5343 - accuracy: 0.8029 - val_loss: 1.2785 - val_accuracy: 0.6407\n",
            "Epoch 5/30\n",
            "147/147 [==============================] - 21s 145ms/step - loss: 0.4845 - accuracy: 0.8181 - val_loss: 1.0355 - val_accuracy: 0.7015\n",
            "Epoch 6/30\n",
            "147/147 [==============================] - 23s 160ms/step - loss: 0.4321 - accuracy: 0.8405 - val_loss: 0.9420 - val_accuracy: 0.7297\n",
            "Epoch 7/30\n",
            "147/147 [==============================] - 23s 154ms/step - loss: 0.3795 - accuracy: 0.8598 - val_loss: 0.8283 - val_accuracy: 0.7228\n",
            "Epoch 8/30\n",
            "147/147 [==============================] - 22s 151ms/step - loss: 0.3470 - accuracy: 0.8715 - val_loss: 1.1002 - val_accuracy: 0.6630\n",
            "Epoch 9/30\n",
            "147/147 [==============================] - 23s 159ms/step - loss: 0.3139 - accuracy: 0.8816 - val_loss: 0.8282 - val_accuracy: 0.7382\n",
            "Epoch 10/30\n",
            "147/147 [==============================] - 21s 146ms/step - loss: 0.2804 - accuracy: 0.9044 - val_loss: 0.7426 - val_accuracy: 0.7836\n",
            "Epoch 11/30\n",
            "147/147 [==============================] - 22s 147ms/step - loss: 0.2618 - accuracy: 0.9062 - val_loss: 0.9489 - val_accuracy: 0.7160\n",
            "Epoch 12/30\n",
            "147/147 [==============================] - 23s 159ms/step - loss: 0.2511 - accuracy: 0.9100 - val_loss: 0.7026 - val_accuracy: 0.7853\n",
            "Epoch 13/30\n",
            "147/147 [==============================] - 22s 150ms/step - loss: 0.2162 - accuracy: 0.9188 - val_loss: 0.9591 - val_accuracy: 0.7399\n",
            "Epoch 14/30\n",
            "147/147 [==============================] - 22s 149ms/step - loss: 0.2007 - accuracy: 0.9256 - val_loss: 1.5886 - val_accuracy: 0.6518\n",
            "Epoch 15/30\n",
            "147/147 [==============================] - 23s 157ms/step - loss: 0.1894 - accuracy: 0.9303 - val_loss: 0.8047 - val_accuracy: 0.7742\n",
            "Epoch 16/30\n",
            "147/147 [==============================] - 23s 158ms/step - loss: 0.1733 - accuracy: 0.9386 - val_loss: 0.9221 - val_accuracy: 0.7605\n",
            "Epoch 17/30\n",
            "147/147 [==============================] - 21s 145ms/step - loss: 0.1567 - accuracy: 0.9470 - val_loss: 0.8735 - val_accuracy: 0.7468\n",
            "Epoch 18/30\n",
            "147/147 [==============================] - 23s 159ms/step - loss: 0.1598 - accuracy: 0.9466 - val_loss: 0.9198 - val_accuracy: 0.7793\n",
            "Epoch 19/30\n",
            "147/147 [==============================] - 21s 146ms/step - loss: 0.1436 - accuracy: 0.9491 - val_loss: 0.9601 - val_accuracy: 0.7519\n",
            "Epoch 20/30\n",
            "147/147 [==============================] - 23s 159ms/step - loss: 0.1421 - accuracy: 0.9498 - val_loss: 0.7453 - val_accuracy: 0.8127\n",
            "Epoch 21/30\n",
            "147/147 [==============================] - 21s 146ms/step - loss: 0.1193 - accuracy: 0.9585 - val_loss: 1.4892 - val_accuracy: 0.7143\n",
            "Epoch 22/30\n",
            "147/147 [==============================] - 22s 150ms/step - loss: 0.1287 - accuracy: 0.9551 - val_loss: 0.8752 - val_accuracy: 0.7921\n",
            "Epoch 23/30\n",
            "147/147 [==============================] - 22s 151ms/step - loss: 0.1161 - accuracy: 0.9581 - val_loss: 0.6480 - val_accuracy: 0.8306\n",
            "Epoch 24/30\n",
            "147/147 [==============================] - 22s 152ms/step - loss: 0.1127 - accuracy: 0.9583 - val_loss: 0.9887 - val_accuracy: 0.7639\n",
            "Epoch 25/30\n",
            "147/147 [==============================] - 23s 158ms/step - loss: 0.1067 - accuracy: 0.9605 - val_loss: 1.1472 - val_accuracy: 0.7613\n",
            "Epoch 26/30\n",
            "147/147 [==============================] - 23s 155ms/step - loss: 0.0916 - accuracy: 0.9694 - val_loss: 1.2150 - val_accuracy: 0.7468\n",
            "Epoch 27/30\n",
            "147/147 [==============================] - 23s 156ms/step - loss: 0.1013 - accuracy: 0.9654 - val_loss: 1.3181 - val_accuracy: 0.7357\n",
            "Epoch 28/30\n",
            "147/147 [==============================] - 22s 153ms/step - loss: 0.0896 - accuracy: 0.9709 - val_loss: 0.8306 - val_accuracy: 0.8349\n",
            "Epoch 29/30\n",
            "147/147 [==============================] - 23s 153ms/step - loss: 0.0960 - accuracy: 0.9681 - val_loss: 0.7866 - val_accuracy: 0.8118\n",
            "Epoch 30/30\n",
            "147/147 [==============================] - 23s 159ms/step - loss: 0.0912 - accuracy: 0.9699 - val_loss: 0.8244 - val_accuracy: 0.8161\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‚â–„â–‚â–„â–…â–„â–‚â–…â–†â–„â–†â–…â–‚â–†â–†â–…â–†â–…â–‡â–„â–‡â–ˆâ–†â–†â–…â–…â–ˆâ–‡â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–„â–„â–‚â–†â–„â–ƒâ–‚â–„â–‚â–‚â–ƒâ–â–ƒâ–ˆâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‡â–ƒâ–â–„â–…â–…â–†â–‚â–‚â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.96986</td></tr><tr><td>epoch/epoch</td><td>29</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.09121</td></tr><tr><td>epoch/val_accuracy</td><td>0.81608</td></tr><tr><td>epoch/val_loss</td><td>0.82444</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">peanut-butter-pie-3</strong> at: <a href='https://wandb.ai/leoliu11/Optimizers/runs/57k48fyx' target=\"_blank\">https://wandb.ai/leoliu11/Optimizers/runs/57k48fyx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>/content/wandb/run-20230314_213346-57k48fyx/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.compile(optimizer=config.optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=config.epochs,\n",
        "  callbacks = [WandbMetricsLogger()])\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rfxkcl4UB4P1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}